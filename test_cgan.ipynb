{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization,Conv2DTranspose, GlobalMaxPooling2D, Conv2D, Reshape\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalGAN(keras.Model):\n",
    "    def __init__(self, \n",
    "                 data_type : str = 'image', \n",
    "                 number_classes : int = 10,\n",
    "                 num_channels : int  = 1,\n",
    "                 problem_size = (28,28),\n",
    "                 discriminator_structure : tuple = (32,64),\n",
    "                 generator_structure : tuple = (16,16),\n",
    "                 discriminator_optimizer : str = 'Adam',\n",
    "                 generator_optimizer : str = 'Adam',\n",
    "                 latent_dim : int = 32,\n",
    "                 activation_discriminator : str = 'linear',\n",
    "                 activation_generator : str = 'linear',\n",
    "                 loss : str = 'binary_crossentropy'):\n",
    "\n",
    "        super(ConditionalGAN, self).__init__()\n",
    "        self.discriminator_structure = discriminator_structure\n",
    "        self.generator_structure = generator_structure\n",
    "        self.latent_dim = latent_dim\n",
    "        self.activation_discriminator = activation_discriminator\n",
    "        self.activation_generator = activation_generator\n",
    "        self.loss = loss\n",
    "\n",
    "        self.number_classes = number_classes\n",
    "        self.data_type = data_type\n",
    "\n",
    "        self.generator_optimizer = generator_optimizer\n",
    "        self.discriminator_optimizer = discriminator_optimizer\n",
    "\n",
    "        self.n_layers_discriminator = len(discriminator_structure)\n",
    "        self.n_layers_generator = len(generator_structure)\n",
    "\n",
    "        self.problem_size = problem_size\n",
    "\n",
    "        self.generator_in_channels = latent_dim + number_classes\n",
    "        self.discriminator_in_channels = num_channels + number_classes\n",
    "\n",
    "        list_prob_size = list(self.problem_size)\n",
    "        list_prob_size.append(number_classes)\n",
    "        self.discriminator_in_shape = tuple(list_prob_size)\n",
    "\n",
    "        self.create_initial_generator_discriminator()\n",
    "        self.generator.describe()\n",
    "        self.discriminator.describe()\n",
    "        #self.generator = self.create_generator()\n",
    "        #self.discriminator = self.create_discriminator()\n",
    "        #print(self.generator_in_channels, self.discriminator_in_channels)\n",
    "        self.compile()\n",
    "\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    def create_initial_generator_discriminator(self):\n",
    "        # Create the discriminator.\n",
    "        discriminator = keras.Sequential(\n",
    "            [\n",
    "                keras.layers.InputLayer((28, 28, self.discriminator_in_channels)),\n",
    "                keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "                keras.layers.LeakyReLU(alpha=0.2),\n",
    "                keras.layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "                keras.layers.LeakyReLU(alpha=0.2),\n",
    "                keras.layers.GlobalMaxPooling2D(),\n",
    "                keras.layers.Dense(1),\n",
    "            ],\n",
    "            name=\"discriminator\",\n",
    "        )\n",
    "\n",
    "        # Create the generator.\n",
    "        generator = keras.Sequential(\n",
    "            [\n",
    "                keras.layers.InputLayer((self.generator_in_channels,)),\n",
    "                # We want to generate 128 + num_classes coefficients to reshape into a\n",
    "                # 7x7x(128 + num_classes) map.\n",
    "                keras.layers.Dense(7 * 7 * self.generator_in_channels),\n",
    "                keras.layers.LeakyReLU(alpha=0.2),\n",
    "                keras.layers.Reshape((7, 7, self.generator_in_channels)),\n",
    "                keras.layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "                keras.layers.LeakyReLU(alpha=0.2),\n",
    "                keras.layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "                keras.layers.LeakyReLU(alpha=0.2),\n",
    "                keras.layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
    "            ],\n",
    "            name=\"generator\",\n",
    "        )\n",
    "\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "\n",
    "\n",
    "\n",
    "    def create_generator(self):\n",
    "\n",
    "        print(\"Generating Generator Network...\")\n",
    "\n",
    "        generator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((self.generator_in_channels,)),\n",
    "        keras.layers.Dense(4 * 4 * self.generator_in_channels),\n",
    "        keras.layers.Reshape((4, 4, self.generator_in_channels)),\n",
    "        keras.layers.UpSampling2D((2,2)),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Conv2DTranspose(self.generator_structure[0], (5, 5), strides=(1, 1), padding=\"valid\",activation=\"relu\"),\n",
    "        keras.layers.UpSampling2D((2,2)),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Conv2DTranspose(1, (5, 5), strides=(1, 1), padding=\"valid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")   \n",
    "        generator.summary()\n",
    "        return generator\n",
    "        \n",
    "        generator = Sequential(name='Generator')\n",
    "        generator.add(tf.keras.layers.InputLayer(input_shape=(self.generator_in_channels)))\n",
    "\n",
    "        if self.data_type.upper() == 'IMAGE' :\n",
    "            generator.add(Dense(7*7 * self.generator_in_channels,activation = self.activation_generator))\n",
    "            generator.add(Reshape((7, 7, self.generator_in_channels)))\n",
    "            for layer in range(self.n_layers_generator):\n",
    "                generator.add(Conv2DTranspose(self.generator_structure[layer],(4,4),strides=(2, 2), padding=\"same\",activation = self.activation_generator))\n",
    "            generator.add(Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"))\n",
    "        else :\n",
    "            for layer in range(self.n_layers_generator):\n",
    "                generator.add(Dense(self.generator_structure[layer],\n",
    "                                    activation = self.activation_generator))\n",
    "                if self.use_batch_norm_generator :\n",
    "                    generator.add(BatchNormalization())\n",
    "\n",
    "            generator.add(Dense(self.n_features,\n",
    "                                activation = self.activation_generator))\n",
    "\n",
    "        generator.summary()\n",
    "        return generator\n",
    "\n",
    "\n",
    "    def create_discriminator(self):\n",
    "\n",
    "        print(\"Generating Discriminator Network...\")\n",
    "\n",
    "\n",
    "        discriminator = keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.InputLayer(input_shape=(self.problem_size[0], \n",
    "                                                self.problem_size[1], \n",
    "                                                self.discriminator_in_channels)), \n",
    "\n",
    "        tf.keras.layers.Conv2D(self.discriminator_structure[0], (5,5), strides=(1, 1), padding=\"valid\",activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.MaxPool2D((2,2)),\n",
    "\n",
    "        tf.keras.layers.Conv2D(self.discriminator_structure[1], (5,5), strides=(1, 1), padding=\"valid\",activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.MaxPool2D((2,2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ],\n",
    "    name=\"Discriminator\",\n",
    ")       \n",
    "        discriminator.summary()\n",
    "        return discriminator\n",
    "\n",
    "        discriminator = Sequential(name='Discriminator')\n",
    "        discriminator.add(tf.keras.layers.InputLayer(input_shape=(self.problem_size[0], \n",
    "                                                                  self.problem_size[1], \n",
    "                                                                  self.discriminator_in_channels)))\n",
    "\n",
    "        if self.data_type.upper() == 'IMAGE' :\n",
    "            for layer in range(self.n_layers_discriminator):\n",
    "                discriminator.add(Conv2D(self.discriminator_structure[layer], (3, 3), strides=(2, 2), padding=\"same\"))\n",
    "            discriminator.add(GlobalMaxPooling2D())\n",
    "        else :\n",
    "\n",
    "            for layer in range(self.n_layers_discriminator):\n",
    "                discriminator.add(Dense(self.discriminator_structure[layer],\n",
    "                                    activation = self.activation_discriminator))\n",
    "                if self.use_batch_norm_discriminator:\n",
    "                    discriminator.add(BatchNormalization())\n",
    "\n",
    "        discriminator.add(Dense(1))\n",
    "        discriminator.summary()\n",
    "\n",
    "        return discriminator \n",
    "\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self):\n",
    "        super(ConditionalGAN, self).compile()\n",
    "        self.d_optimizer = keras.optimizers.Adam(learning_rate=0.0003)\n",
    "        self.g_optimizer = keras.optimizers.Adam(learning_rate=0.0003)\n",
    "        self.loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "\n",
    "    def generate_fake(self,n_fakes,label = None):\n",
    "\n",
    "        if label is None :\n",
    "            label_vec = keras.utils.to_categorical(np.random.randint(0,self.number_classes,size = n_fakes),self.number_classes)\n",
    "            noise =  tf.repeat(tf.random.normal(shape=(1, self.latent_dim)),n_fakes,axis=0)\n",
    "            noise_and_labels = tf.concat([noise, label_vec], 1)\n",
    "\n",
    "        else :\n",
    "            noise =  tf.random.normal(shape=(1, self.latent_dim))\n",
    "            label = keras.utils.to_categorical([label],self.number_classes)\n",
    "            noise_and_labels = tf.repeat(tf.concat([noise, label], 1),n_fakes,axis=0)\n",
    "\n",
    "        return(self.generator.predict(noise_and_labels))\n",
    "        \n",
    "\n",
    "    def train_step(self, data):\n",
    "\n",
    "        # Unpack the data.\n",
    "        real_images, one_hot_labels = data\n",
    "\n",
    "        # Add dummy dimensions to the labels so that they can be concatenated with\n",
    "        # the images. This is for the discriminator.\n",
    "        image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "        image_one_hot_labels = tf.repeat(\n",
    "            image_one_hot_labels, repeats=[self.problem_size[0] * self.problem_size[1]]\n",
    "        )\n",
    "        image_one_hot_labels = tf.reshape(\n",
    "            image_one_hot_labels, (-1, self.problem_size[0], self.problem_size[1], self.number_classes)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space and concatenate the labels.\n",
    "        # This is for the generator.\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Decode the noise (guided by labels) to fake images.\n",
    "        generated_images = self.generator(random_vector_labels)\n",
    "\n",
    "        # Combine them with real images. Note that we are concatenating the labels\n",
    "        # with these images here.\n",
    "        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], -1)\n",
    "        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n",
    "        combined_images = tf.concat(\n",
    "            [fake_image_and_labels, real_image_and_labels], axis=0\n",
    "        )\n",
    "\n",
    "        # Assemble labels discriminating real from fake images.\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "\n",
    "        # Train the discriminator.\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space.\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Assemble labels that say \"all real images\".\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator(random_vector_labels)\n",
    "            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)\n",
    "            predictions = self.discriminator(fake_image_and_labels)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "        # Monitor loss.\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training images: (70000, 28, 28, 1)\n",
      "Shape of training labels: (70000, 10)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_channels = 1\n",
    "num_classes = 10\n",
    "image_size = 28\n",
    "latent_dim = 128\n",
    "\n",
    "\n",
    "# We'll use all the available examples from both the training and test\n",
    "# sets.\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "all_digits = np.concatenate([x_train, x_test])\n",
    "all_labels = np.concatenate([y_train, y_test])\n",
    "\n",
    "# Scale the pixel values to [0, 1] range, add a channel dimension to\n",
    "# the images, and one-hot encode the labels.\n",
    "all_digits = all_digits.astype(\"float32\") / 255.0\n",
    "all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n",
    "all_labels = keras.utils.to_categorical(all_labels, 10)\n",
    "\n",
    "# Create tf.data.Dataset.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((all_digits, all_labels))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "print(f\"Shape of training images: {all_digits.shape}\")\n",
    "print(f\"Shape of training labels: {all_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_gan = ConditionalGAN(num_channels = num_channels,\n",
    "                          number_classes=num_classes,\n",
    "                          problem_size=(image_size,image_size),\n",
    "                          latent_dim=latent_dim,\n",
    "                          discriminator_structure = (128,128),\n",
    "                          generator_structure=(128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "class PlotEpochCallback(keras.callbacks.Callback):\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        generate = epoch%self.model.number_classes\n",
    "        print('Plot fake number {}'.format(generate))\n",
    "        imshow(self.model.generate_fake(1,generate)[0])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [PlotEpochCallback()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cond_gan' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-09020abe51cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcond_gan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'cond_gan' is not defined"
     ]
    }
   ],
   "source": [
    "cond_gan.fit(dataset,epochs=100,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f287ceae80>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(cond_gan.generate_fake(1,5)[0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3f23f82d00c00562bb85a393e3d5f0de6baaf9948c645113797c759b078ed985"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('MLenv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
